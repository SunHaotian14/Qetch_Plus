{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Experiment on Different Time-series Similarity Measures 1"]},{"cell_type":"markdown","metadata":{},"source":["### Loading"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["number of loaded samples per class: [100, 100, 100, 100, 100, 100, 100, 100]\n","Original data: 8 datasets\n","Sketch data: 8 datasets\n"]}],"source":["# load image and libraries\n","%matplotlib inline\n","from matplotlib import cm\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from itertools import groupby\n","from scipy import signal\n","from sklearn import preprocessing\n","import pandas as pd\n","\n","plt.rcParams['figure.figsize'] = [10, 5]\n","plt.rcParams['figure.dpi'] = 150 # 200 e.g. is really fine, but slower\n","\n","root_path = './processed_datasets/'\n","datasets = ['has', 'sp', 'fp', 'rb', 'sd', 'sr', 'hasb', 'ihas']\n","\n","# load ground truth\n","ori_data_X = []\n","ori_data_y = []\n","sketch_X = []\n","for dataset in datasets:\n","    file_name = root_path + 'original_' + dataset  \n","    ori_data_X.append(np.load(file_name + '_X' + '.npy'))\n","    ori_data_y.append(np.load(file_name + '_y' + '.npy'))\n","    file_name = root_path + 'sketch_' + dataset + '.npy'\n","    sketch_X.append(np.load(file_name, allow_pickle=True)[:100])\n","print(f\"number of loaded samples per class: {[len(x) for x in sketch_X]}\")\n","print(f\"Original data: {len(ori_data_X)} datasets\")\n","print(f\"Sketch data: {len(sketch_X)} datasets\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Sliding Window"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def sliding_window(ori_series, clip_series, measure):\n","    \"\"\"\n","    Compute the similarities of the original and the clipped series using sliding window\n","    input: original time series, clipped series, similarity measure function\n","    output: similarity_distribution, matching result, i.e., starting and ending points\n","    \"\"\"\n","    ori_len = ori_series.shape[0]\n","    clip_len = clip_series.shape[0]\n","    if ori_len < clip_len:\n","        return None\n","\n","    # compute the similarity between the original and the clipped series\n","    dist = []\n","    # compute the similarity between the original and the clipped series using sliding window\n","    for i in range(ori_len - clip_len + 1):\n","        dist.append(measure(ori_series[i:i+clip_len], clip_series))\n","    # find the maximum similarity and the corresponding starting and ending points\n","    min_idx = np.argmin(dist)\n","    return dist, [min_idx, min_idx + clip_len - 1]\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def pointwise_exp(ori_data_X, ori_data_y, sketch_X, measure):\n","    results = []\n","    for i, dataset in enumerate(datasets):\n","        original = ori_data_X[i]\n","        label = ori_data_y[i]\n","        dummy_record = []\n","        for sample in sketch_X[i]:\n","            clip =  signal.resample(sample, label[1]-label[0]+1)\n","            sim_dist, pred_loc = sliding_window(original, clip, measure)\n","            dummy_record.append([sim_dist, pred_loc])\n","        results.append(dummy_record)\n","    return results"]},{"cell_type":"markdown","metadata":{},"source":["### Define Metrics"]},{"cell_type":"markdown","metadata":{},"source":["#### Euclidean Distance"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def euclidean_distance(x,y):\n","    t = preprocessing.Normalizer()\n","    x = np.expand_dims(x, axis=0)\n","    y = np.expand_dims(y, axis=0)\n","    return np.linalg.norm(t.transform(x) - t.transform(y))"]},{"cell_type":"markdown","metadata":{},"source":["#### DTW\n","Based on tslearn: https://github.com/tslearn-team/tslearn/"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from tslearn.metrics import dtw, cdist_dtw\n","def dtw_distance(x,y):\n","    t = preprocessing.Normalizer()\n","    x = np.expand_dims(x, axis=0)\n","    y = np.expand_dims(y, axis=0)\n","    return dtw(t.transform(x)[0], t.transform(y)[0])"]},{"cell_type":"markdown","metadata":{},"source":["### MASS Algorithm (if having time to examine..)\n","https://github.com/matrix-profile-foundation/mass-ts"]},{"cell_type":"markdown","metadata":{},"source":["### Qetch Algorithm"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["#Qetch Algorithm -- inclomplete --\n","\n","def width(series):\n","    # Should return width of series\n","\n","\n","    return \n","    \n","def height(series):\n","    # Should return width of series\n","\n","    return \n","\n","def get_LDE(sketch_split,Candidate_split,Gx,Gy):\n","    Rx = width(Candidate_split)/(Gx * width(sketch_split))    \n","    Ry = height(Candidate_split)/(Gy * height(sketch_split))  \n","    return (np.log(Rx)**2)+(np.log(Ry)**2)\n","\n","def get_ShapeError(Sketch,Candidate,Gx,Gy,k):\n","\n","\n","    return \n","def calculatDistance(Sketch, Candidate,k):\n","    # Calculating Global non uniform Scaling facctors\n","    Gx = width(Candidate)/width(Sketch)\n","    Gy = height(Candidate)/height(Sketch)\n","    # Calculating Shape error\n","    SE = get_ShapeError(Sketch,Candidate,Gx,Gy)\n","    sketch_split = np.split(Sketch,k)\n","    Candidate_split = np.split(Candidate,k)\n","    # Calculating Local distortion errors\n","    LDE = 0\n","    for i in range(k):\n","        LDE += get_LDE(Sketch[i],Candidate[i],Gx,Gy,k)\n","\n","    # Calculating total error\n","    Dist = LDE + SE\n","    return Dist\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Experiment 1: Matching Performance"]},{"cell_type":"markdown","metadata":{},"source":["#### Analysis"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def analyze_results(results, plot = True, ori_data_X=ori_data_X, ori_data_Y=ori_data_y, datasets=datasets):\n","    d = {'Dataset':[], 'Number of samples':[], 'Average distance':[], 'Average location error (%)':[]}\n","    \n","    for i in range(len(results)):\n","        d['Dataset'].append(datasets[i])\n","        d['Number of samples'].append(len(results[i]))\n","        d['Average distance'].append(np.mean([np.max(x[0]) for x in results[i]]))\n","        d['Average location error (%)'].append(np.mean([np.abs(x[1][0] - ori_data_y[i][0])/ ori_data_X[i].shape[0]*100 for x in results[i]]))\n","        dummy = {\"Dataset\": datasets[i], \"Number of samples\": len(results[i]), \"Average distance\": np.mean([np.max(x[0]) for x in results[i]]),\n","                 \"Average location error (%)\": np.mean([np.abs(x[1][0] - ori_data_y[i][0])/ ori_data_X[i].shape[0]*100 for x in results[i]])}\n","    df = pd.DataFrame(d)\n","    display(df)\n","    display(df.iloc[:,[2,3]].describe())\n","    print(f'Average location error w.r.t. total length: {np.mean([np.mean([np.abs(x[1][0] - ori_data_y[i][0])/ ori_data_X[i].shape[0]*100 for x in results[i]]) for i in range(len(results))])}%')\n","    print('--------------------------------------------------------')\n","    if plot:\n","        plt.figure()\n","        for i in range(len(results)):\n","            ax = plt.subplot(3,3,i+1)\n","            plt.tight_layout()\n","            plt.title(f\"Dataset: {datasets[i]}\")\n","            plt.xlabel(\"Time\")\n","            plt.ylabel(\"Distance\")\n","            plt.plot(results[i][0][0])\n","            plt.plot(results[i][0][1], [0.5, 0.5], marker='*', ls='none')\n","            plt.plot(ori_data_y[i], [0.5, 0.5], marker='o', color='r', ls='none')\n","        plt.legend(['Distance', 'Predicted', 'Ground Truth'],bbox_to_anchor=(2,0), loc='lower right')\n","        plt.show()\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["#### Get results"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Measure: euclidean_distance\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dataset</th>\n","      <th>Number of samples</th>\n","      <th>Average distance</th>\n","      <th>Average location error (%)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>has</td>\n","      <td>100</td>\n","      <td>0.868820</td>\n","      <td>7.251208</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sp</td>\n","      <td>100</td>\n","      <td>0.894325</td>\n","      <td>17.347826</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fp</td>\n","      <td>100</td>\n","      <td>1.026507</td>\n","      <td>12.874396</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>rb</td>\n","      <td>100</td>\n","      <td>1.139434</td>\n","      <td>1.932367</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sd</td>\n","      <td>100</td>\n","      <td>0.586013</td>\n","      <td>3.045894</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>sr</td>\n","      <td>100</td>\n","      <td>1.239033</td>\n","      <td>23.241546</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>hasb</td>\n","      <td>100</td>\n","      <td>0.669684</td>\n","      <td>8.983092</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>ihas</td>\n","      <td>100</td>\n","      <td>0.752768</td>\n","      <td>10.975904</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Dataset  Number of samples  Average distance  Average location error (%)\n","0     has                100          0.868820                    7.251208\n","1      sp                100          0.894325                   17.347826\n","2      fp                100          1.026507                   12.874396\n","3      rb                100          1.139434                    1.932367\n","4      sd                100          0.586013                    3.045894\n","5      sr                100          1.239033                   23.241546\n","6    hasb                100          0.669684                    8.983092\n","7    ihas                100          0.752768                   10.975904"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Average distance</th>\n","      <th>Average location error (%)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.897073</td>\n","      <td>10.706529</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.227572</td>\n","      <td>7.137291</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.586013</td>\n","      <td>1.932367</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.731997</td>\n","      <td>6.199879</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.881572</td>\n","      <td>9.979498</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.054739</td>\n","      <td>13.992754</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.239033</td>\n","      <td>23.241546</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Average distance  Average location error (%)\n","count          8.000000                    8.000000\n","mean           0.897073                   10.706529\n","std            0.227572                    7.137291\n","min            0.586013                    1.932367\n","25%            0.731997                    6.199879\n","50%            0.881572                    9.979498\n","75%            1.054739                   13.992754\n","max            1.239033                   23.241546"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average location error w.r.t. total length: 10.706529014609162%\n","--------------------------------------------------------\n","Measure: dtw_distance\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dataset</th>\n","      <th>Number of samples</th>\n","      <th>Average distance</th>\n","      <th>Average location error (%)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>has</td>\n","      <td>100</td>\n","      <td>0.678415</td>\n","      <td>7.176329</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sp</td>\n","      <td>100</td>\n","      <td>0.621693</td>\n","      <td>12.927536</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fp</td>\n","      <td>100</td>\n","      <td>0.707616</td>\n","      <td>11.314010</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>rb</td>\n","      <td>100</td>\n","      <td>0.858138</td>\n","      <td>1.553140</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>sd</td>\n","      <td>100</td>\n","      <td>0.442453</td>\n","      <td>2.927536</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>sr</td>\n","      <td>100</td>\n","      <td>1.058595</td>\n","      <td>16.120773</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>hasb</td>\n","      <td>100</td>\n","      <td>0.565764</td>\n","      <td>19.599034</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>ihas</td>\n","      <td>100</td>\n","      <td>0.593285</td>\n","      <td>2.886747</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Dataset  Number of samples  Average distance  Average location error (%)\n","0     has                100          0.678415                    7.176329\n","1      sp                100          0.621693                   12.927536\n","2      fp                100          0.707616                   11.314010\n","3      rb                100          0.858138                    1.553140\n","4      sd                100          0.442453                    2.927536\n","5      sr                100          1.058595                   16.120773\n","6    hasb                100          0.565764                   19.599034\n","7    ihas                100          0.593285                    2.886747"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Average distance</th>\n","      <th>Average location error (%)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>8.000000</td>\n","      <td>8.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.690745</td>\n","      <td>9.313138</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.190977</td>\n","      <td>6.719575</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.442453</td>\n","      <td>1.553140</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.586405</td>\n","      <td>2.917339</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.650054</td>\n","      <td>9.245169</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.745247</td>\n","      <td>13.725845</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.058595</td>\n","      <td>19.599034</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Average distance  Average location error (%)\n","count          8.000000                    8.000000\n","mean           0.690745                    9.313138\n","std            0.190977                    6.719575\n","min            0.442453                    1.553140\n","25%            0.586405                    2.917339\n","50%            0.650054                    9.245169\n","75%            0.745247                   13.725845\n","max            1.058595                   19.599034"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Average location error w.r.t. total length: 9.313138059484315%\n","--------------------------------------------------------\n"]}],"source":["measures = [euclidean_distance, dtw_distance]\n","for measure in measures:\n","    print(f\"Measure: {measure.__name__}\")\n","    results = pointwise_exp(ori_data_X, ori_data_y, sketch_X, measure)\n","    df = analyze_results(results, plot = False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"7565caab8eb65219391f22c8065d75359b61fe2354d09a736de30f82e6269c7c"}}},"nbformat":4,"nbformat_minor":2}
